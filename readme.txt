# readme file by xueaoru

> xueaoru 

> 新人往下看看git版本管理工具基本命令

## 文件结构
main.py 入口文件
detect.py 识别灯条和装甲板
make_feature_map.py 基于PCA的特征提取，用于数字分类。快就完事了。
config.py 配置管理文件
config.cfg 配置文件
cap_manager.py 相机管理文件，用来获取每帧图片，bayer bg8 格式 + 3000曝光时间 = 1 ~ 3 ms 每张图片 
utils/serial.py 串口通信文件
graph.pb tensorflow 三分类model，mobile-net V3 的改进版，没有结构图，此电脑上没有网络结构代码
MvImport/* 相机头文件


## nn思路
之前相机比较差，代码写的也比较乱，现在相机很好，代码也实现了模块化。主要思路就是用工业相机得到一个frame，只要相机够好，相机本身的fps和分辨率足够大，就能保证很小的卡顿，然后对每个frame做一些滤波处理，设置一个比较大的颜色范围，这样能保证灯条能被识别到，设计一个轻量的网络结构，使得网络的前向速度非常理想，我是先用DenseNet强网络对提取的红色灯条、蓝色灯条、背景做三分类训练，强网络的结果就作为gt去训练自己设计的MobileNet V3改进版（原始网络的参数量和计算量仍然可以减少，看你怎么设计，但是要保证网络的拟合能力够），这样弱网络也就具有了三分类能力，而且前向速度极快。之后对每个灯条做三分类，保留所需要分类的灯条。之后根据面积差值、角度差值的加权做匹配，最终匹配到两者加权差最小的作为最终的装甲板。然后输出装甲板的中间坐标。
## 训练
使用知识蒸馏方法训练，teacher网络使用的是densenet121,student网络使用的是改进的mobilenet v3.

## 单项赛定制版思路
不使用nn，相机本身优化到1~3ms每张图片，调整合适的曝光，只进行hsv控制，全图寻找目标，条件筛选，灯条匹配，单向赛根据车型小陀螺大致为方形，因此看到四个灯条的情况必定为中间两个灯条组成一个装甲板。在这之前考虑了用任意两灯条之间数字threshold之后的亮点比例来做判别，仍存在一定误差，有时候挺有效果，取决于车的装饰。后弃而不用。算法目前已经优化了很多，最有效的是动态roi，识别到目标之后会领域搜索，而不是整张图搜索，故加速明显。串口单独一个线程。debug和非debug模式下帧数差别比较大，因为耗时大都花在图片显示上，故非debug模式下帧数会高很多。usb3.0口在靠近风扇那一侧。不要在程序运行的时候直接断电，因为会导致相机参数重置，导致程序无法运行（比赛前1min出现此bug）。串口线一定要用胶粘紧，不然问题也是大大的（比赛前1min又出现此bug）。

## 其他
cap_manager.py 实现了图像获取和根据配置进行录像，这个是很必要的，录下实际比赛的时候的视频对我们学习很有帮助。
config.py 实现了配置自动保存自动加载等功能，这样不需要每次都调参，减少复杂度。
用了tensorrt加速计算，大概能省10ms的时间。
tensorflow 必须用1.8版本的，太低没有集成tensorrt，1.9有bug，1.10以上版本太高用不了。


## 将要做
装甲板测距 STATE：TODO 相机标定，pnp算法，得到旋转矩阵，得到pitch,yaw
位置预测   STATE：DONE 分为旋转模式和普通模式，旋转模式下往运动方向上加补偿。
号码识别   STATE：DONE 基于矩阵论的知识，对装甲板矩阵拉平，所有图片组成特征矩阵然后均值化，PCA后得到特征阵，新样本先均值化，然后乘以降唯矩阵得到feature向量，对比每个训练集合feature和测试及feature欧式距离阈值下进行判别。

## 时间统计
相机获取图片 1~3ms
所有图像处理时间 roi 4ms
无roi 8ms

## git版本管理工具的使用
> git init 初始化
> git add  添加文件
> git commit -m '' 提交修改
> git log 历史记录
> git reset --hard xx 回退版本
> git reflog 操作记录,回到未来


新朋友请不要随便版本回退，修改完记得git commit，像rm这种命令还是不知道的好。commit的信息记得填上自己的名字！


